{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MayaYakimova/homework/blob/main/7_%D1%81%D0%B5%D0%BC_%D0%B4%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D1%8F%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y7k_JhqMHUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "182815c2-5ebb-4075-832f-a3c845ca447b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7f27b40fba80>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.add_pipe('sentencizer')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В целях исследования были выбраны фрагменты произведений Чарльза Диккенса. Его иногда называют \"английским Толстым\" за любовь к порой мучительно длинным предложениям. Данная обработка текста сможет помочь в дальнейшей работе и изучении работ писателя."
      ],
      "metadata": {
        "id": "zAKOPyNnwV8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"В корпусе 4 документа: our_mutual_friend.txt, bleak_house.txt, pickwick_papers.txt, hard_times.txt\")\n",
        "\n",
        "with open('our_mutual_friend.txt', 'r', encoding='utf-8') as f:\n",
        "    friend_text = f.read()\n",
        "friend_text = friend_text.replace('\\n', ' ')\n",
        "\n",
        "with open('bleak_house.txt', 'r', encoding='utf-8') as f:\n",
        "    house_text = f.read()\n",
        "house_text = house_text.replace('\\n', ' ')\n",
        "\n",
        "with open('pickwick_papers.txt', 'r', encoding='utf-8') as f:\n",
        "    papers_text = f.read()\n",
        "papers_text = papers_text.replace('\\n', ' ')\n",
        "\n",
        "with open('hard_times.txt', 'r', encoding='utf-8') as f:\n",
        "    hard_text = f.read()\n",
        "hard_text = hard_text.replace('\\n', ' ')\n",
        "\n",
        "# В корпусе 4 документа: our_mutual_friend.txt, bleak_house.txt, pickwick_papers.txt, hard_times.txt"
      ],
      "metadata": {
        "id": "D_AhrzhqwUuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f8d634-edb1-4695-e3fd-7dd9865986e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "В корпусе 4 документа: our_mutual_friend.txt, bleak_house.txt, pickwick_papers.txt, hard_times.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(friend_text)\n",
        "doc2 = nlp(house_text)\n",
        "doc3 = nlp(papers_text)\n",
        "doc4 = nlp(hard_text)"
      ],
      "metadata": {
        "id": "oDh1sgkFwYdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Количество слов в каждом тексте\n",
        "\n",
        "words1 = []\n",
        "for token in doc1:\n",
        "  if token.text.isalnum():\n",
        "    words1.append(token.text)\n",
        "print(words1[:100])\n",
        "\n",
        "words2 = []\n",
        "for token in doc2:\n",
        "  if token.text.isalnum():\n",
        "    words2.append(token.text)\n",
        "print(words2[:100])\n",
        "\n",
        "words3 = []\n",
        "for token in doc3:\n",
        "  if token.text.isalnum():\n",
        "    words3.append(token.text)\n",
        "print(words3[:100])\n",
        "\n",
        "words4 = []\n",
        "for token in doc4:\n",
        "  if token.text.isalnum():\n",
        "    words4.append(token.text)\n",
        "print(words4[:100])\n",
        "\n",
        "print(f\"В тексте 'Our Mutual Friend' {len(words1)} слов.\")\n",
        "print(f\"В тексте 'Bleak House' {len(words2)} слов.\")\n",
        "print(f\"В тексте 'Pickwick Papers' {len(words3)} слов.\")\n",
        "print(f\"В тексте 'Hard Times' {len(words4)} слов.\")\n",
        "tot_words = len(words1) + len(words2) + len(words3) + len(words4)"
      ],
      "metadata": {
        "id": "zenlS6KywaY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4253717e-6b0c-45bb-89df-5abc4a90784d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['In', 'these', 'times', 'of', 'ours', 'though', 'concerning', 'the', 'exact', 'year', 'there', 'is', 'no', 'need', 'to', 'be', 'precise', 'a', 'boat', 'of', 'dirty', 'and', 'disreputable', 'appearance', 'with', 'two', 'figures', 'in', 'it', 'floated', 'on', 'the', 'Thames', 'between', 'Southwark', 'bridge', 'which', 'is', 'of', 'iron', 'and', 'London', 'Bridge', 'which', 'is', 'of', 'stone', 'as', 'an', 'autumn', 'evening', 'was', 'closing', 'in', 'The', 'figures', 'in', 'this', 'boat', 'were', 'those', 'of', 'a', 'strong', 'man', 'with', 'ragged', 'grizzled', 'hair', 'and', 'a', 'sun', 'browned', 'face', 'and', 'a', 'dark', 'girl', 'of', 'nineteen', 'or', 'twenty', 'sufficiently', 'like', 'him', 'to', 'be', 'recognizable', 'as', 'his', 'daughter', 'The', 'girl', 'rowed', 'pulling', 'a', 'pair', 'of', 'sculls', 'very']\n",
            "['London', 'Michaelmas', 'term', 'lately', 'over', 'and', 'the', 'Lord', 'Chancellor', 'sitting', 'in', 'Lincoln', 'Inn', 'Hall', 'Implacable', 'November', 'weather', 'As', 'much', 'mud', 'in', 'the', 'streets', 'as', 'if', 'the', 'waters', 'had', 'but', 'newly', 'retired', 'from', 'the', 'face', 'of', 'the', 'earth', 'and', 'it', 'would', 'not', 'be', 'wonderful', 'to', 'meet', 'a', 'Megalosaurus', 'forty', 'feet', 'long', 'or', 'so', 'waddling', 'like', 'an', 'elephantine', 'lizard', 'up', 'Holborn', 'Hill', 'Smoke', 'lowering', 'down', 'from', 'chimney', 'pots', 'making', 'a', 'soft', 'black', 'drizzle', 'with', 'flakes', 'of', 'soot', 'in', 'it', 'as', 'big', 'as', 'full', 'grown', 'snowflakes', 'gone', 'into', 'mourning', 'one', 'might', 'imagine', 'for', 'the', 'death', 'of', 'the', 'sun', 'Dogs', 'undistinguishable', 'in', 'mire', 'Horses']\n",
            "['CHAPTER', 'THE', 'PICKWICKIANS', 'The', 'first', 'ray', 'of', 'light', 'which', 'illumines', 'the', 'gloom', 'and', 'converts', 'into', 'a', 'dazzling', 'brilliancy', 'that', 'obscurity', 'in', 'which', 'the', 'earlier', 'history', 'of', 'the', 'public', 'career', 'of', 'the', 'immortal', 'Pickwick', 'would', 'appear', 'to', 'be', 'involved', 'is', 'derived', 'from', 'the', 'perusal', 'of', 'the', 'following', 'entry', 'in', 'the', 'Transactions', 'of', 'the', 'Pickwick', 'Club', 'which', 'the', 'editor', 'of', 'these', 'papers', 'feels', 'the', 'highest', 'pleasure', 'in', 'laying', 'before', 'his', 'readers', 'as', 'a', 'proof', 'of', 'the', 'careful', 'attention', 'indefatigable', 'assiduity', 'and', 'nice', 'discrimination', 'with', 'which', 'his', 'search', 'among', 'the', 'multifarious', 'documents', 'confided', 'to', 'him', 'has', 'been', 'conducted', 'May', '12', '1827', 'Joseph', 'Smiggers']\n",
            "['CHAPTER', 'I', 'THE', 'ONE', 'THING', 'NEEDFUL', 'NOW', 'what', 'I', 'want', 'is', 'Facts', 'Teach', 'these', 'boys', 'and', 'girls', 'nothing', 'but', 'Facts', 'Facts', 'alone', 'are', 'wanted', 'in', 'life', 'Plant', 'nothing', 'else', 'and', 'root', 'out', 'everything', 'else', 'You', 'can', 'only', 'form', 'the', 'minds', 'of', 'reasoning', 'animals', 'upon', 'Facts', 'nothing', 'else', 'will', 'ever', 'be', 'of', 'any', 'service', 'to', 'them', 'This', 'is', 'the', 'principle', 'on', 'which', 'I', 'bring', 'up', 'my', 'own', 'children', 'and', 'this', 'is', 'the', 'principle', 'on', 'which', 'I', 'bring', 'up', 'these', 'children', 'Stick', 'to', 'Facts', 'sir', 'The', 'scene', 'was', 'a', 'plain', 'bare', 'monotonous', 'vault', 'of', 'a', 'school', 'room', 'and', 'the', 'speaker', 'square', 'forefinger']\n",
            "В тексте 'Our Mutual Friend' 30416 слов.\n",
            "В тексте 'Bleak House' 2088 слов.\n",
            "В тексте 'Pickwick Papers' 95978 слов.\n",
            "В тексте 'Hard Times' 33654 слов.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {}\n",
        "c1, c2, c3, c4 = 0, 0, 0, 0\n",
        "\n",
        "for sent in doc1.sents:\n",
        "  doc = nlp(sent.text)\n",
        "  w = 0\n",
        "  for token in doc:\n",
        "    if token.text.isalnum():\n",
        "      w += 1\n",
        "  if w not in dic:\n",
        "    dic[w] = 1\n",
        "  else:\n",
        "    dic[w] += 1\n",
        "  c1 += 1\n",
        "\n",
        "\n",
        "for sent in doc2.sents:\n",
        "  doc = nlp(sent.text)\n",
        "  w = 0\n",
        "  for token in doc:\n",
        "    if token.text.isalnum():\n",
        "      w += 1\n",
        "  if w not in dic:\n",
        "    dic[w] = 1\n",
        "  else:\n",
        "    dic[w] += 1\n",
        "  c2 += 1\n",
        "\n",
        "\n",
        "for sent in doc3.sents:\n",
        "  doc = nlp(sent.text)\n",
        "  w = 0\n",
        "  for token in doc:\n",
        "    if token.text.isalnum():\n",
        "      w += 1\n",
        "  if w not in dic:\n",
        "    dic[w] = 1\n",
        "  else:\n",
        "    dic[w] += 1\n",
        "  c3 += 1\n",
        "\n",
        "\n",
        "for sent in doc4.sents:\n",
        "  doc = nlp(sent.text)\n",
        "  w = 0\n",
        "  for token in doc:\n",
        "    if token.text.isalnum():\n",
        "      w += 1\n",
        "  if w not in dic:\n",
        "    dic[w] = 1\n",
        "  else:\n",
        "    dic[w] += 1\n",
        "  c4 += 1\n",
        "\n",
        "\n",
        "print(f\"В тексте 'Our Mutual Friend' {c1} предложений.\")\n",
        "print(f\"В тексте 'Bleak House' {c2} предложений.\")\n",
        "print(f\"В тексте 'Pickwick Papers' {c3} предложений.\")\n",
        "print(f\"В тексте 'Hard Times' {c4} предложений.\")\n"
      ],
      "metadata": {
        "id": "xD8AHDfOwcAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb2e15c-d4e3-418f-8304-5ce3a4f6c87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "В тексте 'Our Mutual Friend' 1675 предложений.\n",
            "В тексте 'Bleak House' 64 предложений.\n",
            "В тексте 'Pickwick Papers' 4991 предложений.\n",
            "В тексте 'Hard Times' 1963 предложений.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tot_words = 0\n",
        "for x in dic:\n",
        "  tot_words += x*dic[x]\n",
        "print(tot_words)\n",
        "\n",
        "words = 0\n",
        "sents = 0\n",
        "for x in range(1, 11):\n",
        "  if x in dic:\n",
        "    words += x*(dic[x])\n",
        "    sents += dic[x]\n",
        "print(\"1-10 cлов\")\n",
        "print(f\"{words} слов всего\")\n",
        "print(f\"{(round(words/tot_words*100, 1))}% ({sents} предложений)\")\n",
        "print()\n",
        "\n",
        "words = 0\n",
        "sents = 0\n",
        "for x in range(11, 21):\n",
        "  if x in dic:\n",
        "    words += x*(dic[x])\n",
        "    sents += dic[x]\n",
        "print(\"11-21 cлово\")\n",
        "print(f\"{words} слов всего\")\n",
        "print(f\"{(round(words/tot_words*100, 1))}% ({sents} предложений)\")\n",
        "print()\n",
        "\n",
        "words = 0\n",
        "sents = 0\n",
        "for x in range(21, 31):\n",
        "  if x in dic:\n",
        "    words += x*(dic[x])\n",
        "    sents += dic[x]\n",
        "print(\"21-31 cлово\")\n",
        "print(f\"{words} слов всего\")\n",
        "print(f\"{(round(words/tot_words*100, 1))}% ({sents} предложений)\")\n",
        "print()\n",
        "\n",
        "words = 0\n",
        "sents = 0\n",
        "for x in range(31, 41):\n",
        "  if x in dic:\n",
        "    words += x*(dic[x])\n",
        "    sents += dic[x]\n",
        "print(\"31-41 cлово\")\n",
        "print(f\"{words} слов всего\")\n",
        "print(f\"{(round(words/tot_words*100, 1))}% ({sents} предложений)\")\n",
        "print()\n",
        "\n",
        "words = 0\n",
        "sents = 0\n",
        "for x in range(41, 51):\n",
        "  if x in dic:\n",
        "    words += x*(dic[x])\n",
        "    sents += dic[x]\n",
        "print(\"41-51 cлово\")\n",
        "print(f\"{words} слов всего\")\n",
        "print(f\"{(round(words/tot_words*100, 1))}% ({sents} предложений)\")\n",
        "print()\n",
        "\n",
        "words = 0\n",
        "sents = 0\n",
        "for x in range(51, 61):\n",
        "  if x in dic:\n",
        "    words += x*(dic[x])\n",
        "    sents += dic[x]\n",
        "print(\"51-61 cлово\")\n",
        "print(f\"{words} слов всего\")\n",
        "print(f\"{(round(words/tot_words*100, 1))}% ({sents} предложений)\")\n",
        "print()\n",
        "\n",
        "words = 0\n",
        "sents = 0\n",
        "for x in range(61, 71):\n",
        "  if x in dic:\n",
        "    words += x*(dic[x])\n",
        "    sents += dic[x]\n",
        "print(\"61-71 cлово\")\n",
        "print(f\"{words} слов всего\")\n",
        "print(f\"{(round(words/tot_words*100, 1))}% ({sents} предложений)\")\n",
        "print()\n",
        "\n",
        "words = 0\n",
        "sents = 0\n",
        "for x in dic:\n",
        "  if x > 70:\n",
        "    words += x*(dic[x])\n",
        "    sents += dic[x]\n",
        "print(\"Более 70 слов\")\n",
        "print(f\"{words} слов всего\")\n",
        "print(f\"{(round(words/tot_words*100, 1))}% ({sents} предложений)\")\n",
        "print()"
      ],
      "metadata": {
        "id": "gN3lCnfOweWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d720f52-8548-4b13-a918-120c393506b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162138\n",
            "1-10 cлов\n",
            "20306 слов всего\n",
            "12.5% (3577 предложений)\n",
            "\n",
            "11-21 cлово\n",
            "33565 слов всего\n",
            "20.7% (2248 предложений)\n",
            "\n",
            "21-31 cлово\n",
            "32421 слов всего\n",
            "20.0% (1296 предложений)\n",
            "\n",
            "31-41 cлово\n",
            "24143 слов всего\n",
            "14.9% (685 предложений)\n",
            "\n",
            "41-51 cлово\n",
            "16256 слов всего\n",
            "10.0% (358 предложений)\n",
            "\n",
            "51-61 cлово\n",
            "12098 слов всего\n",
            "7.5% (219 предложений)\n",
            "\n",
            "61-71 cлово\n",
            "8655 слов всего\n",
            "5.3% (133 предложений)\n",
            "\n",
            "Более 70 слов\n",
            "14694 слов всего\n",
            "9.1% (166 предложений)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}